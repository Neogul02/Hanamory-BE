import os
from pathlib import Path
import uuid
import gc
import psutil
import time
import torch
from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
from PIL import Image

# CPU ìµœì í™” ì„¤ì •
os.environ['OMP_NUM_THREADS'] = '1'
os.environ['MKL_NUM_THREADS'] = '1'
os.environ['TORCH_NUM_THREADS'] = '1'
os.environ['TORCH_WEIGHTS_ONLY'] = 'False'

# ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).resolve().parent
MODEL_PATH = BASE_DIR / 'models' / 'best.pt'
UPLOAD_DIR = BASE_DIR / 'static' / 'uploads'
RESULT_DIR = BASE_DIR / 'static' / 'results'

# ì„¤ì •ê°’
IMGSZ = (640, 640)
CONF_THRES = 0.5
MAX_DET = 50
MAX_IMAGE_SIZE = 800

# ë””ë ‰í† ë¦¬ ìƒì„±
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)
RESULT_DIR.mkdir(parents=True, exist_ok=True)

app = Flask(__name__)
CORS(app)

# ì „ì—­ ëª¨ë¸ ë³€ìˆ˜
global_model = None

def load_model():
    """ëª¨ë¸ ë¡œë”©"""
    global global_model
    if global_model is None:
        try:
            torch.set_num_threads(1)
            print(f"ëª¨ë¸ ë¡œë”© ì‹œë„: {MODEL_PATH}")

            if MODEL_PATH.exists():
                # í•™ìŠµëœ ëª¨ë¸ ë¡œë”©
                global_model = torch.hub.load('ultralytics/yolov5', 'custom',
                                            path=str(MODEL_PATH),
                                            force_reload=False,
                                            trust_repo=True)
                print("âœ“ í•™ìŠµëœ flower2 ëª¨ë¸ ë¡œë”© ì™„ë£Œ")
            else:
                # ê¸°ë³¸ ëª¨ë¸ ì‚¬ìš©
                global_model = torch.hub.load('ultralytics/yolov5', 'yolov5s',
                                            pretrained=True,
                                            trust_repo=True)
                print("âœ“ ê¸°ë³¸ YOLOv5s ëª¨ë¸ ë¡œë”© ì™„ë£Œ")

            global_model.to('cpu')
            global_model.eval()
            global_model.conf = CONF_THRES
            global_model.max_det = MAX_DET

        except Exception as e:
            print(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
            global_model = None
    return global_model

def optimize_image(image_path, max_size=MAX_IMAGE_SIZE):
    """ì´ë¯¸ì§€ ìµœì í™”"""
    try:
        with Image.open(image_path) as img:
            if img.mode != 'RGB':
                img = img.convert('RGB')

            if max(img.size) > max_size:
                ratio = max_size / max(img.size)
                new_size = tuple(int(dim * ratio) for dim in img.size)
                img = img.resize(new_size, Image.Resampling.LANCZOS)

            img.save(image_path, 'JPEG', quality=85, optimize=True)
            return True
    except Exception as e:
        print(f"ì´ë¯¸ì§€ ìµœì í™” ì‹¤íŒ¨: {e}")
        return False

@app.route('/', methods=['GET'])
def home():
    return jsonify({
        "message": "YOLOv5 Flower Detection API",
        "version": "Final",
        "model": "flower2_yolov5" if MODEL_PATH.exists() else "yolov5s",
        "status": "running"
    })

@app.route('/health', methods=['GET'])
def health():
    cpu_percent = psutil.cpu_percent(interval=0.1)
    memory_percent = psutil.virtual_memory().percent

    return jsonify({
        "status": "healthy",
        "cpu_usage": f"{cpu_percent:.1f}%",
        "memory_usage": f"{memory_percent:.1f}%",
        "model_loaded": global_model is not None,
        "model_path": str(MODEL_PATH),
        "model_exists": MODEL_PATH.exists()
    })

@app.route('/predict', methods=['POST'])
def predict():
    # CPU ì‚¬ìš©ë¥  ì²´í¬
    cpu_percent = psutil.cpu_percent(interval=0.1)
    if cpu_percent > 95.0:
        return jsonify({'error': 'CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'}), 503

    if 'image' not in request.files:
        return jsonify({'error': 'ì´ë¯¸ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400

    file = request.files['image']
    if file.filename == '':
        return jsonify({'error': 'íŒŒì¼ì´ ì„ íƒë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}), 400

    # íŒŒì¼ëª… ìƒì„±
    filename = f"{uuid.uuid4().hex}.jpg"
    input_path = UPLOAD_DIR / filename
    result_path = RESULT_DIR / filename

    try:
        # íŒŒì¼ í¬ê¸° ì²´í¬
        file.seek(0, 2)
        file_size = file.tell()
        file.seek(0)

        if file_size > 10 * 1024 * 1024:  # 10MB
            return jsonify({'error': 'íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ í½ë‹ˆë‹¤. (ìµœëŒ€ 10MB)'}), 413

        # íŒŒì¼ ì €ì¥ ë° ìµœì í™”
        file.save(str(input_path))
        if not optimize_image(input_path):
            return jsonify({'error': 'ì´ë¯¸ì§€ ìµœì í™” ì‹¤íŒ¨'}), 400

        # ëª¨ë¸ ë¡œë”©
        model = load_model()
        if model is None:
            return jsonify({'error': 'ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨'}), 500

        # ì˜ˆì¸¡ ì‹¤í–‰
        with torch.no_grad():
            results = model(str(input_path), size=IMGSZ[0])

        # ê²°ê³¼ ì´ë¯¸ì§€ ì €ì¥ (ì§ì ‘ ì €ì¥)
        results.save(save_dir=str(RESULT_DIR))

        # ê²°ê³¼ íŒŒì¼ ì°¾ê¸° - ëª¨ë“  results í´ë”ì—ì„œ ê²€ìƒ‰
        result_path = None

        # results, results2, results3 ë“± ëª¨ë“  í´ë”ì—ì„œ ê²€ìƒ‰
        results_dirs = []
        base_static_dir = BASE_DIR / 'static'

        # ëª¨ë“  results ê´€ë ¨ í´ë” ì°¾ê¸°
        for item in base_static_dir.iterdir():
            if item.is_dir() and item.name.startswith('results'):
                results_dirs.append(item)

        # ê°€ì¥ ìµœê·¼ì— ìƒì„±ëœ ì´ë¯¸ì§€ íŒŒì¼ ì°¾ê¸°
        all_result_files = []
        for results_dir in results_dirs:
            result_files = list(results_dir.glob("*.jpg"))
            all_result_files.extend(result_files)

        if all_result_files:
            # ê°€ì¥ ìµœê·¼ ìƒì„±ëœ íŒŒì¼ ì„ íƒ
            latest_file = max(all_result_files, key=lambda x: x.stat().st_mtime)

            # ì˜ˆì¸¡ ê°€ëŠ¥í•œ ì´ë¦„ìœ¼ë¡œ ë³µì‚¬
            final_result_path = RESULT_DIR / filename

            # ê²°ê³¼ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
            RESULT_DIR.mkdir(parents=True, exist_ok=True)

            # íŒŒì¼ ë³µì‚¬
            import shutil
            shutil.copy2(str(latest_file), str(final_result_path))
            result_path = final_result_path

            print(f"ê²°ê³¼ ì´ë¯¸ì§€ ë³µì‚¬: {latest_file} -> {final_result_path}")

        if result_path and result_path.exists():
            return send_file(result_path, mimetype='image/jpeg')
        else:
            return jsonify({'error': 'ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 500

    except Exception as e:
        print(f"ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")
        return jsonify({'error': f'ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'}), 500
    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if input_path.exists():
            try:
                input_path.unlink()
            except:
                pass
        gc.collect()

@app.route('/predict-json', methods=['POST'])
def predict_json():
    # CPU ì‚¬ìš©ë¥  ì²´í¬
    cpu_percent = psutil.cpu_percent(interval=0.1)
    if cpu_percent > 85.0:
        return jsonify({'error': 'CPU ì‚¬ìš©ë¥ ì´ ë†’ìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'}), 503

    if 'image' not in request.files:
        return jsonify({'error': 'ì´ë¯¸ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤.'}), 400

    file = request.files['image']
    filename = f"{uuid.uuid4().hex}.jpg"
    input_path = UPLOAD_DIR / filename

    try:
        file.save(str(input_path))
        if not optimize_image(input_path):
            return jsonify({'error': 'ì´ë¯¸ì§€ ìµœì í™” ì‹¤íŒ¨'}), 400

        model = load_model()
        if model is None:
            return jsonify({'error': 'ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨'}), 500

        # ì˜ˆì¸¡ ì‹¤í–‰
        with torch.no_grad():
            results = model(str(input_path), size=IMGSZ[0])

        predictions = []

        if hasattr(results, 'xyxy') and len(results.xyxy) > 0:
            detections = results.xyxy[0].cpu().numpy()

            for detection in detections:
                if len(detection) >= 6:
                    x1, y1, x2, y2, conf, cls = detection[:6]

                    if conf >= CONF_THRES:
                        predictions.append({
                            'class': model.names[int(cls)] if hasattr(model, 'names') else f'class_{int(cls)}',
                            'confidence': round(float(conf), 4),
                            'bbox': [round(float(x1), 2), round(float(y1), 2),
                                   round(float(x2), 2), round(float(y2), 2)]
                        })

        return jsonify({
            'predictions': predictions,
            'count': len(predictions),
            'image_size': IMGSZ,
            'model_name': 'flower2_yolov5' if MODEL_PATH.exists() else 'yolov5s'
        })

    except Exception as e:
        print(f"predict-json ì˜¤ë¥˜: {e}")
        return jsonify({'error': f'ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}'}), 500
    finally:
        if input_path.exists():
            try:
                input_path.unlink()
            except:
                pass
        gc.collect()

if __name__ == '__main__':
    print("ğŸš€ YOLOv5 Flask Server ì‹œì‘...")
    print(f"ğŸ“Š ì„¤ì •: ì´ë¯¸ì§€ í¬ê¸°={IMGSZ}, ì‹ ë¢°ë„={CONF_THRES}")
    print(f"ğŸ¯ ëª¨ë¸: {'í•™ìŠµëœ flower2 ëª¨ë¸' if MODEL_PATH.exists() else 'ê¸°ë³¸ YOLOv5s ëª¨ë¸'}")

    # ëª¨ë¸ ë¯¸ë¦¬ ë¡œë”©
    load_model()

    app.run(host='0.0.0.0', port=5000, debug=False)
